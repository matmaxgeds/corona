dec = ".")
per
class(per)
names(per)
a<-" anything goes here, STR1 GET_ME STR2, anything goes here"
a
res <- str_match(a, "STR1 (.*?) STR2")
res
# Extract names of locations
namesVEC <- str_match(linksVEC, "2018. (.*?) .tmp.per")
namesVEC
# Extract names of locations
namesVEC <- str_match(linksVEC, "2018\. (.*?) \.tmp\.per")
# Extract names of locations
namesVEC <- str_match(linksVEC, "2018 (.*?) tmp")
namesVEC
regmatches(linksVEC, regexec("2018 (.*?) tmp",linksVEC))
test <- linksVEC[1]
test
str_match(test, "2018 (.*?) tmp")
regmatches(test, regexpr("2018\\s*\\K.*?(?=\\s*tmp)", test, perl=TRUE))
regmatches(test, regexpr("2018\.\\s*\\K.*?(?=\\s*\.tmp)", test, perl=TRUE))
regmatches(test, regexpr("2018.\\s*\\K.*?(?=\\s*.tmp)", test, perl=TRUE))
# Extract names of locations
namesVEC <- regmatches(linksVEC,
regexpr("2018.\\s*\\K.*?(?=\\s*.tmp)", linksVEC, perl=TRUE))
namesVEC
per
help("read.delim")
per <- read.delim(file = "./raw/weatherTemp.per",
sep = "\t",
dec = ".",
header = FALSE)
View(per)
per <- read.delim(file = "./raw/weatherTemp.per",
sep = "\t",
dec = ".",
skip = 3,
header = TRUE)
View(per)
per <- read.delim(file = "./raw/weatherTemp.per",
sep = "\t",
dec = ".",
skip = 2,
header = TRUE)
per <- read.delim(file = "./raw/weatherTemp.per",
sep = "\t",
dec = ".",
header = TRUE)
names(per)
library(data.table)
library(data.table)
per <- fread("./raw/weatherTemp.per")
per
dim(per)
names(per)
per <- per %>%
dplyr::select(YEAR:DEC) %>%
pivot_longer(cols = JAN:DEC,
names_to = "month",
values_to = "temp")
dim(per)
head(per)
per <- fread(file = "./raw/weatherTemp.per")
per <- per %>%
dplyr::select(YEAR:DEC) %>%
pivot_longer(cols = JAN:DEC,
names_to = "month",
values_to = "temp") %>%
filter(YEAR==2018 & month %in% c("JAN","FEB","MAR"))
per
tempLIST <- data.frame(country = namesVEC,
temp = NA)
rm(tempLIST)
tempDF <- data.frame(country = namesVEC,
temp = NA)
head(tempDF)
rm(namesVEC)
namesVEC <- regmatches(linksVEC,
regexpr("2018.\\s*\\K.*?(?=\\s*.tmp)", linksVEC, perl=TRUE))
extractWeather <- function(x) {
# Produce list in which data sets are to be saved
tempDF <- data.frame(country = namesVEC,
temp = NA)
for(i in 1:length(x)) {
download.file(x[i],
"./raw/weatherTemp.per",
mode = "wb",
quiet = TRUE)
per <- fread(file = "./raw/weatherTemp.per")
per <- per %>%
dplyr::select(YEAR:DEC) %>%
pivot_longer(cols = JAN:DEC,
names_to = "month",
values_to = "temp") %>%
filter(YEAR==2018 & month %in% c("JAN","FEB","MAR")) %>%
mutate(temp = if_else(temp==-999, NA_integer_, temp))
tempDF$temp[i] <- mean(per$temp, na.rm = TRUE)
}
tempDF
}
temperatureDF <- extractWeather(linksVEC)
extractWeather <- function(x) {
# Produce list in which data sets are to be saved
tempDF <- data.frame(country = namesVEC,
temp = NA)
for(i in 1:length(x)) {
download.file(x[i],
"./raw/weatherTemp.per",
mode = "wb",
quiet = TRUE)
per <- fread(file = "./raw/weatherTemp.per")
per <- per %>%
dplyr::select(YEAR:DEC) %>%
pivot_longer(cols = JAN:DEC,
names_to = "month",
values_to = "temp") %>%
filter(YEAR==2018 & month %in% c("JAN","FEB","MAR")) %>%
mutate(temp = as.numeric(temp)) %>%
mutate(temp = if_else(temp==-999, NA_real_, temp))
tempDF$temp[i] <- mean(per$temp, na.rm = TRUE)
}
tempDF
}
temperatureDF <- extractWeather(linksVEC)
temperatureDF
55.7/3
# Cleanup
file.remove("./raw/weatherTemp.per")
#### PRECIPITATION DATA ####
# Measured in mm/month
# Extract links from website, so as to be able to use them for data reading
page <- read_html("https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_4.03/crucy.1905151143.v4.03/new_countries/pre/")
linksVEC <- page %>%
html_nodes("a") %>%
html_attr("href")
linksVEC[1:10]
linksVEC <- linksVEC[7:length(linksVEC)]
rm(page)
linksVEC <- paste0("https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_4.03/crucy.1905151143.v4.03/new_countries/pre/",
linksVEC)
linksVEC[1:10]
namesVEC <- regmatches(linksVEC,
regexpr("2018.\\s*\\K.*?(?=\\s*.pre)", linksVEC, perl=TRUE))
length(linksVEC)
length(namesVEC)
precipitationDF <- extractWeather(linksVEC)
precipitationDF
# Cleanup
file.remove("./raw/weatherTemp.per")
precipitationDF <- precipitationDF %>%
rename(precip = temp)
head(precipitationDF)
dim(temperatureDF)
weatherDF <- left_join(temperatureDF,
precipitationDF,
by = "country")
dim(weatherDF)
View(weatherDF)
write.csv(weatherDF,file = "~/Desktop/weather.csv", row.names = FALSE)
rm(temperatureDF, precipitationDF)
corona <- read.csv("./saved/corona.csv")
setdiff(weatherDF$country, unique(corona$countriesAndTerritories))
unique(corona$countriesAndTerritories)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
check.packages <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE,
repos = "https://cran.rstudio.com")
sapply(pkg, require, character.only = TRUE)
}
pkgList <- c("RCurl","WDI","readxl","httr","knitr","tidyverse",
"estimatr","stargazer","countrycode","dataverse",
"zip", "lubridate", "rvest", "fastDummies", "lfe",
"directlabels", "kableExtra", "ggrepel")
check.packages(pkgList)
## Should Lasso analysis be re-run?
rerun_lasso <- FALSE
lasso_res <- read_rds("saved/lasso_res.rds")
names(lasso_res)
? glmnet
names(lasso_res$lcoef_pol)
plot_df <- lcoef %>% distinct(Y_labels, .keep_all = T) %>%
filter(outcome %in% c('deaths_cumul_log', 'deaths_cumul_per_million')) %>%
dplyr::select(Y_labels, rmse_allobs, rmse_cv) %>%
mutate(ss = 'Excluding political / social correlates') %>%
pivot_longer(cols = c('rmse_allobs', 'rmse_cv'), names_to = 'rmse_type') %>%
mutate(rmse_type = dplyr::recode(rmse_type,
`rmse_allobs` = 'RMSE, full sample',
`rmse_cv` = 'Avg. RMSE, 5-fold CV'))
if(Y == "deaths_cumul_per_million"){
dropped_countries <-   dropped_pc
} else {
dropped_countries <-  dropped
}
shiny::runApp('C:/Dropbox/github/gbiqq_shiny')
df <- read.csv(saved/df.csv)
df <- read.csv("saved/df.csv")
View(filter(df, GeoId == "NA"))
View(filter(df, Country.Code == "NAM"))
View(filter(corona, Country.Code == "NAM"))
corona <- read.csv("saved/corona.csv") %>%
rename(GeoId = geoId,
Cases = cases,
Deaths = deaths,
DateRep = dateRep)%>%
mutate(date = as.Date(DateRep)) %>%
dplyr::select(-c(year,month,day))
View(corona)
table(corona$GeoId)
str(corona$GeoId)
? read.csv
corona <- read.csv("saved/corona.csv", stringsAsFactors = FALSE) %>%
rename(GeoId = geoId,
Cases = cases,
Deaths = deaths,
DateRep = dateRep)%>%
mutate(date = as.Date(DateRep)) %>%
dplyr::select(-c(year,month,day))
str(corona$GeoId)
View(filter(corona, Country.Code == "NAM"))
View(corona)
corona <- read.csv("saved/corona.csv", stringsAsFactors = FALSE) %>%
rename(GeoId = geoId,
Cases = cases,
Deaths = deaths,
DateRep = dateRep)%>%
mutate(date = as.Date(DateRep)) %>%
dplyr::select(-c(year,month,day)) %>%
mutate(GeoId = ifelse(countriesAndTerritories=="Namibia", "NA",countriesandTerritories))
corona <- read.csv("saved/corona.csv", stringsAsFactors = FALSE) %>%
rename(GeoId = geoId,
Cases = cases,
Deaths = deaths,
DateRep = dateRep)%>%
mutate(date = as.Date(DateRep)) %>%
dplyr::select(-c(year,month,day)) %>%
mutate(GeoId = ifelse(countriesAndTerritories=="Namibia", "NA", countriesAndTerritories))
corona <- read.csv("saved/corona.csv", stringsAsFactors = FALSE) %>%
rename(GeoId = geoId,
Cases = cases,
Deaths = deaths,
DateRep = dateRep)%>%
mutate(date = as.Date(DateRep)) %>%
dplyr::select(-c(year,month,day)) %>%
mutate(GeoId = ifelse(countriesAndTerritories=="Namibia", "NA", countriesAndTerritories))
rectangle <- expand_grid(unique(corona$GeoId), seq(as.Date(min(corona$date)),
as.Date(max(corona$date)),
by = "day"))
names(rectangle) <- c("GeoId", "date")
rectangle <- rectangle %>%
mutate(month = format(as.POSIXct(date), "%m"),
day = format(as.POSIXct(date), "%d"),
year = format(as.POSIXct(date), "%Y"),
elapsed = as.integer(-1 + date - min(date)))
corona <- left_join(rectangle, corona) %>%
arrange(GeoId, elapsed) %>%
mutate(Deaths = ifelse(is.na(Deaths), 0, Deaths),
Cases = ifelse(is.na(Cases), 0, Cases))%>%
group_by(GeoId) %>%
mutate(cases_cumul = cumsum(Cases),
deaths_cumul = cumsum(Deaths),
deaths_cumul_log = log(1+deaths_cumul),
cases_L1 = lag(Cases, order_by = elapsed),
cases_L3 = lag(Cases, n = 3, order_by = elapsed),
cases_L14 = lag(Cases, n = 14, order_by = elapsed),
cases_cumul_L1 = lag(cases_cumul, order_by = elapsed),
cases_cumul_L3 = lag(cases_cumul, n = 3, order_by = elapsed),
cases_cumul_L7 = lag(cases_cumul, n = 7, order_by = elapsed),
cases_cumul_L14 = lag(cases_cumul, n = 14, order_by = elapsed),
cases_cumul_g1 = lag(cases_cumul/cases_cumul_L1 - 1, order_by = elapsed),
cases_cumul_g1 = ifelse(cases_cumul_g1 == Inf, NA, cases_cumul_g1),
cases_cumul_g3 = lag(cases_cumul/cases_cumul_L3 - 1, order_by = elapsed),
cases_cumul_g3 = ifelse(cases_cumul_g3 == Inf, NA, cases_cumul_g3),
deaths_L1 = lag(Deaths, order_by = elapsed),
deaths_L2 = lag(Deaths, n = 2, order_by = elapsed),
deaths_L3 = lag(Deaths, n = 3, order_by = elapsed),
deaths_cumul_L1 = lag(deaths_cumul, order_by = elapsed),
deaths_cumul_L3 = lag(deaths_cumul, n = 3, order_by = elapsed),
deaths_cumul_g1 = lag(deaths_cumul/deaths_cumul_L1 - 1, order_by = elapsed),
deaths_cumul_g1 = ifelse(deaths_cumul_g1 == Inf, NA, deaths_cumul_g1),
deaths_cumul_g3 = lag(deaths_cumul/deaths_cumul_L3 - 1, order_by = elapsed),
deaths_cumul_g3 = ifelse(deaths_cumul_g3 == Inf, NA, deaths_cumul_g3)
) %>%
ungroup() #%>%
View(df)
f_dag <- function(x,
y,
names,
arcs = cbind(0,0),
add_points = FALSE,
solids = rep(1, length(x)),
title = "",
contraction = .1,
add_functions = 0,
add_functions_text = NULL,
text_shift = .2*add_points,
padding = .5,
length = 0.2,
cex = 1,
box = TRUE) {
if(add_points)  plot(x, y, pch=ifelse(solids == 1, 19, 1), cex = 2, axes = FALSE, xlab = "", ylab = "",
xlim = c(min(x)-padding, max(x)+padding),
ylim = c(min(y)-padding-add_functions, max(y)+padding),
main = title)
if(!add_points)  plot(x, y, type = "n", cex = 2, axes = FALSE, xlab = "", ylab = "",
xlim = c(min(x)-padding, max(x)+padding),
ylim = c(min(y)-padding-add_functions, max(y)+padding),
main = title)
arrow_length = ((x[arcs[,1]] - x[arcs[,2]])^2 + (y[arcs[,1]] - y[arcs[,2]])^2)^.5
arrow_length <-  arrow_length/max(arrow_length)
contraction  <- (1-3*arrow_length/4)*contraction
arrows(x[arcs[,1]]*(1-contraction) + x[arcs[,2]]*contraction,
y[arcs[,1]]*(1-contraction) + y[arcs[,2]]*contraction,
x[arcs[,2]]*(1-contraction) + x[arcs[,1]]*contraction,
y[arcs[,2]]*(1-contraction) + y[arcs[,1]]*contraction, length = length)
text(x, y + text_shift, names, cex = cex)
if(!is.null(add_functions_text)) text(((min(x)+max(x))/2), min(y)-1, add_functions_text)
if(box) box()
}
dagdf <- data.frame(
x = c(1,1,1,2,  3, 4.5,4,6.5, 5.5,5,6,7),
y = c(1,2,3,1.5,2, 3,  2,3,   3,  2,2,1.5),
names = c("3. Social\nStructures",
"2. Political\nInstitutions",
"1. State\nCapacity",
"Government\nIncentives",
"Policies",
"4. Global Linkages \n 5. Physical risks",
"Behaviors /\nCompliance",
"7. Health\nSystem",
"6. Health \n Risks",
"Infections",
"Deaths",
"Reported\nDeaths"),
position = 1:12)
dagdf
format(Sys.time(), "%Y-%m-%d")
format(Sys.time(), "%Y-%m-%d"-1)
format(Sys.time(), "%Y-%m-%d")-1
format(Sys.time(), "%Y-%m-%d")-1
format(Sys.time() -1, "%Y-%m-%d")
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
check.packages <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE,
repos = "https://cran.rstudio.com")
sapply(pkg, require, character.only = TRUE)
}
pkgList <- c("RCurl","WDI","readxl","httr","knitr","tidyverse",
"estimatr","stargazer","countrycode","dataverse",
"zip", "lubridate", "rvest", "fastDummies", "lfe",
"directlabels", "kableExtra", "ggrepel")
check.packages(pkgList)
## Should Lasso analysis be re-run?
rerun_lasso <- FALSE
if (rerun_lasso) {
## rerun lasso code here
}
## Load all Lasso results
lasso_res <- read_rds("saved/lasso_res.rds")
# get data
measures <- read.csv("measures.csv") %>% filter(include == 1)
#controls <- measures[measures$family=="controls", ]$vars %>% as.character
#controls_labels <- measures[measures$family=="controls", ]$labels %>% as.character
lasso_1 <- lasso_res$lcoef_controls %>% filter(outcome == "deaths_cumul_log" & abs(coef)>0) %>%
filter(!duplicated(vars)) %>% filter(rank(-abs(coef))<=4)
controls <- lasso_1$vars
controls_labels <- lasso_1$labels
## Controls for deaths/capita
lasso_2 <- lasso_res$lcoef_controls %>% filter(outcome == "deaths_cumul_per_million" & abs(coef)>0) %>%
filter(!duplicated(vars)) %>% filter(rank(-abs(coef))<=4)
controls_deaths_capita <- lasso_2$vars
controls_deaths_capita_labels <- lasso_2$labels
## Combine control vectors into list
controls_use <- list(controls, controls_deaths_capita)
##
df  <- read.csv("saved/df.csv")
data_date <- max(as.Date(df$DateRep), na.rm = TRUE)
df_today  <- df %>% filter(as.Date(df$DateRep) == data_date)
df_today_no_China  <- df %>% filter(as.Date(df$DateRep) == data_date & GeoId != "CN")
df %>% filter(as.Date(df$DateRep) == data_date & deaths_cumul > 10) %>%
mutate(group = if_else(gdppc > median(gdppc, na.rm = TRUE),
paste0("GDP/capita > ",
paste0(round(1000*round(median(gdppc, na.rm = TRUE)), 0), " USD PPP")),
paste0("GDP/capita < ",
paste0(round(1000*round(median(gdppc, na.rm = TRUE)), 0), " USD PPP")))) %>%
filter(!is.na(group)) %>%
mutate(countriesAndTerritories = str_replace_all(countriesAndTerritories, "_", " ")) %>%
ggplot(aes(x = reorder(countriesAndTerritories, deaths_cumul_log+1),
y = deaths_cumul)) +
geom_point(shape = 21, fill = 'white') +
labs(x = "Country",
y = "Total deaths (log scale)") +
theme_bw() +
theme(panel.grid.major = element_blank()) +
facet_wrap(group ~ ., scales = "free_y", ncol = 2) +
scale_y_continuous(trans='log10') +
coord_flip()
df_reg <- df  %>%
group_by(region, elapsed) %>% summarize(region_deaths_cuml = sum(deaths_cumul, na.rm = TRUE)) %>%
group_by(forcats::fct_explicit_na(region)) %>%
mutate(relative_start = ifelse(any(region_deaths_cuml >= 1),    min(elapsed[region_deaths_cuml >= 1]), NA),
elapsed_rel = elapsed - relative_start) %>%
ungroup() %>%
filter(elapsed_rel > -1 & !is.na(region))
df_reg %>%
ggplot(aes(x=elapsed_rel, y=region_deaths_cuml + 1, color = region)) +
geom_line() +
theme_bw() +
theme(panel.grid.minor = element_blank()) +
xlab("Days since 1st death") +
ylab("Cumulative deaths") +
geom_dl(aes(label = region), method = list(dl.trans(x = x + .2), "last.points")) +
theme(legend.position = "none")+
scale_y_continuous(trans='log10') + xlim(0, max(df_reg$elapsed_rel, na.rm=TRUE) + 15)
df2 <- filter(df_today, deaths_cumul > 10)
df2 %>%
mutate(do_label = ifelse(!between(((1+poptot*1000) * (1+deaths_cumul)),
quantile((1+poptot*1000) * (1+deaths_cumul), 0.05, na.rm= T),
quantile((1+poptot*1000) * (1+deaths_cumul), 0.7, na.rm= T)),
1, 0)) %>%
ggplot(aes(x=1+poptot*1000, y=1+deaths_cumul)) +
geom_point(alpha = 0.5, size = 2) +
xlab("Population")+
ylab("Cumulative deaths") +
theme_bw() +
scale_y_continuous(trans='log10') +
scale_x_continuous(trans='log10') +
theme(panel.grid.minor = element_blank()) +
ggrepel::geom_text_repel(data = . %>% filter(do_label == 1),
aes(label = GeoId))
M1 <- lm_robust(deaths_cumul ~ poptot, data = df_today_no_China)
M2 <- lm_robust(log(deaths_cumul+1) ~ log(poptot+1), data = df_today_no_China)
df %>% filter(elapsed_rel == 30 & GeoId != "SM") %>%
mutate(do_label = ifelse((gdppc * log(1+deaths_cumul_per_million)) >
quantile(gdppc * log(1+deaths_cumul_per_million), 0.655, na.rm= T),
1, 0)) %>%
ggplot(aes(gdppc, deaths_cumul_per_million+1)) +
geom_point(alpha = 0.5, size = 2) +
xlab("Per capita GDP (USD '000)")+
ylab("Deaths / million") +
theme_bw() +
theme(panel.grid.minor = element_blank()) +
scale_y_continuous(trans='log10') +
ggrepel::geom_text_repel(data = . %>% filter(do_label == 1),
aes(label = GeoId))
M <- lm_robust(as.formula(paste("deaths_cumul_log ~ ", paste(controls, collapse = "+"))),
data = filter(df, as.Date(df$DateRep) == data_date))
df <- mutate(filter(df, as.Date(df$DateRep) == data_date), yhay = M$fitted.values)
df_temp  <- mutate(filter(df, as.Date(df$DateRep) == data_date), yhat = M$fitted.values)
M$fitted.values
M <- lm_robust(as.formula(paste("deaths_cumul_log ~ ", paste(controls, collapse = "+"))),
data = filter(df, as.Date(df$DateRep) == data_date))
data = filter(df, as.Date(df$DateRep) == data_date)
dim(data)
length(M$fitted.values)
oos_plot <- function(
data = df_today_no_China,
depvar = "deaths_cumul_log",
controls,
ylabel = "Actual Deaths (logged)",
export_data = FALSE) {
formula = paste(depvar, "~", paste(controls, collapse = "+"))
pred <- function(case, data) {
M <- lm(as.formula(formula), data = filter(data, GeoId != case))
c(actual = data[,depvar][data$GeoId == case],
prediction = predict(M, filter(data, GeoId == case), se.fit = FALSE))
}
oos <- cbind(
case = unique(data$GeoId),
sapply(unique(data$GeoId), function(case) (pred(case, data))) %>% t %>% data.frame()) %>%
filter(!is.na(prediction.1)) %>%
rename(pred = prediction.1) %>%
mutate(resid_abs = abs(pred-actual)) %>%
mutate(do_label = ifelse(resid_abs > quantile(resid_abs, 0.85)  | actual >  quantile(actual, 0.9) | pred > quantile(pred, 0.9),
1, 0))
## Plot
oos %>%
ggplot(aes(pred, actual)) +
geom_point(alpha = 0.5, size = 2) +
xlab("Prediction based on experiences elsewhere")+
ylab(ylabel) +
geom_abline(slope = 1, intercept = 0, linetype = 'dotted') +
theme_bw() +
theme(panel.grid.minor = element_blank()) +
ggrepel::geom_text_repel(data = . %>% filter(do_label == 1),
aes(label = case))
if(export_data) oos
}
df4 <- oos_plot(controls = contols)
df4 <- oos_plot(controls = controls)
filter(df4, GeoId %in% c("JM", "CU", "DO"))
df4
df4 <- oos_plot(controls = controls, export_data = TRUE)
df4
filter(df4, GeoId %in% c("JM", "CU", "DO"))
filter(df4, case  %in% c("JM", "CU", "DO"))
oos_plot(controls = controls, export_data = TRUE) %>% filter(case  %in% c("JM", "CU", "DO"))
View(filter(df_today, GeoId  %in% c("JM", "CU", "DO") )
)
df  <- read.csv("saved/df.csv")
data_date <- max(as.Date(df$DateRep), na.rm = TRUE)
df_today  <- df %>% filter(as.Date(df$DateRep) == data_date)
View(filter(df_today, GeoId  %in% c("JM", "CU", "DO") ))
d5 <- filter(df_today, GeoId  %in% c("JM", "CU", "DO") )
d5$lockdown_bin
d5$distancing_bin
